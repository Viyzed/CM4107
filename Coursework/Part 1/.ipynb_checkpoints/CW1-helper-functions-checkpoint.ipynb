{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for CW1\n",
    "Code provided in this notebook can be copied over to your python notebooks as required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "#for the sigmoid function we need expit() from scipy\n",
    "import scipy.special\n",
    "import os\n",
    "# helper to load data from PNG image files# helpe \n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob\n",
    "# helps to manipulate the image for rotation \n",
    "from scipy import ndimage\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to create a new image by rotating a given image\n",
    "\n",
    "The rotate_image function accepts inputs of size 784 corresponding to a single digit. It then reshapes it to 28*28 image before rotating clockwise and anticlockwise by a given degree. Thereafter returns both newwly created versions of the digit. \n",
    "You will be able to use this in Task 1.3 to create new training data to test ANN and / or kNN.\n",
    "Remember when using this function to insert new training instances you must ensure that the class label is inserted to the corresponding targets array; otherwise you will not be able to use the new data within your machine learning algorithms when for instance training the ANN:\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, batch_size, epochs)\n",
    "n.train(X_train, y_train)\n",
    "\n",
    "OR when initialising the kNN with the augmented train data and class labels:\n",
    "kNN(X_train, Y_train) functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(inputs, degree):\n",
    "  \n",
    "    ## create rotated variations\n",
    "    # rotated anticlockwise by x degrees\n",
    "    inputs_plusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), degree, cval=0.01, order=1, reshape=False)\n",
    "    new_inputs1 = inputs_plusx_img.reshape(784)\n",
    "    # rotated clockwise by x degrees\n",
    "    inputs_minusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), -degree, cval=0.01, order=1, reshape=False)\n",
    "    new_inputs2 = inputs_minusx_img.reshape(784)\n",
    "    \n",
    "    return (new_inputs1, new_inputs2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_my_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-81bdcc18c57a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#rotate an image by a given degree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(instance.reshape(28,28))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnew_image1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_image2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_my_test' is not defined"
     ]
    }
   ],
   "source": [
    "#rotate an image by a given degree\n",
    "degree = 50\n",
    "instance = X_my_test[3]\n",
    "#print(instance.reshape(28,28))\n",
    "new_image1, new_image2 = rotate_image(instance, degree)\n",
    "# show rotated image\n",
    "image_array = np.asfarray(new_image1).flatten().reshape((28,28))\n",
    "# print the grid in grey scale\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.4\n",
    "For kNN you need to use get_my_test_data to load and convert your handwritten digits for the algorithm. \n",
    "\n",
    "For ANN you need to use both get_my_test_data and map_target_to_output_layer to load and convert your handwritten digits for the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for loading your hand written digits\n",
    "In Task 1.4 you will be creating png files of your own handwritten digits and exploring how your algorithms perform when classifying these. \n",
    "\n",
    "The get_my_test_images function below takes a relative path as an input parameter and reads all the *.png files that are there. It then looks at the character just before the extension '.png' and considers this char as the class label. \n",
    "\n",
    "So for instance if you had an image called ../my_images/my_char_paper_9.png then it will extract 9 and use that as the class label. \n",
    "Therefore if you wish to use the function below make sure that the class of the digit appears just before the extension of the image file. Ensure that all your images are in a subfolder such as 'my_images'\n",
    "\n",
    "Note that the returned X and y from this function is already in the format that will be acceptable for kNN's test function. However to use it on ANN you need to further process the class labels (i.e. y) such that they are aligned to the output nodes. For this , we have also provided a further function below:\n",
    "helper_function_ann(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_test_data(folder):\n",
    "    # our own image test data set\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # to read jpg change the regex to '/*.jpg'\n",
    "    folder_expr = folder + '/*.png'\n",
    "    print(folder_expr)\n",
    "\n",
    "    for image_file_name in glob.glob(folder_expr): \n",
    "        print (\"loading ... \", image_file_name)\n",
    "\n",
    "        # load image data from png files into an array\n",
    "        img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "        # reshape from 28x28 to list of 784 values, invert values\n",
    "        img_data  = 255.0 - img_array.reshape(784)\n",
    "        # then scale data to range from 0.01 to 1.0\n",
    "        inputs = (img_data / 255.0 * 0.99) + 0.01\n",
    "        \n",
    "        # use the filename to set the correct label\n",
    "        digit_class = int(image_file_name[-5:-4]) #negative indices for indexing from the end of the array\n",
    "        \n",
    "        X.insert(len(X), inputs)\n",
    "        y.insert(len(y), digit_class)\n",
    "       \n",
    "        pass\n",
    "    return(X,y)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_images/*.png\n",
      "loading ...  my_images\\0.png\n",
      "loading ...  my_images\\1.png\n",
      "loading ...  my_images\\2.png\n",
      "loading ...  my_images\\2828_my_own_2.png\n",
      "loading ...  my_images\\2828_my_own_3.png\n",
      "loading ...  my_images\\2828_my_own_4.png\n",
      "loading ...  my_images\\2828_my_own_5.png\n",
      "loading ...  my_images\\2828_my_own_6.png\n",
      "loading ...  my_images\\2828_my_own_image_3.png\n",
      "loading ...  my_images\\2828_my_own_noisy_6.png\n",
      "loading ...  my_images\\3.png\n",
      "loading ...  my_images\\4.png\n",
      "loading ...  my_images\\5.png\n",
      "loading ...  my_images\\6.png\n",
      "loading ...  my_images\\7.png\n",
      "loading ...  my_images\\8.png\n",
      "loading ...  my_images\\9.png\n",
      "loading ...  my_images\\digit0.png\n",
      "loading ...  my_images\\digit1.png\n",
      "loading ...  my_images\\digit2.png\n",
      "loading ...  my_images\\digit3.png\n",
      "loading ...  my_images\\digit4.png\n",
      "loading ...  my_images\\digit5.png\n",
      "loading ...  my_images\\digit6.png\n",
      "loading ...  my_images\\digit7.png\n",
      "loading ...  my_images\\digit8.png\n",
      "loading ...  my_images\\digit9.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ef10099b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26ef0d558d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_my_test, y_my_test = get_my_test_data('my_images') # my_images is a subfolder in the current folder \n",
    "\n",
    "# lets plot one of the created images that was read into X_my_test\n",
    "# now reshape the 784 features into a 28x28 grid\n",
    "# here asfarray helps to convert values into real numbers\n",
    "image_array = np.asfarray(X_my_test[4]).flatten().reshape((28,28))\n",
    "\n",
    "# print the grid in grey scale\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to prepare my image test data for ANN\n",
    "\n",
    "Specific functions to convert the data into the input and output format that is suited for the ANN class (in ANN.ipynb).\n",
    "Here the class label value needs to be maped in to a format aligned to the output_nodes layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_images/*.png\n",
      "loading ...  my_images\\0.png\n",
      "loading ...  my_images\\1.png\n",
      "loading ...  my_images\\2.png\n",
      "loading ...  my_images\\2828_my_own_2.png\n",
      "loading ...  my_images\\2828_my_own_3.png\n",
      "loading ...  my_images\\2828_my_own_4.png\n",
      "loading ...  my_images\\2828_my_own_5.png\n",
      "loading ...  my_images\\2828_my_own_6.png\n",
      "loading ...  my_images\\2828_my_own_image_3.png\n",
      "loading ...  my_images\\2828_my_own_noisy_6.png\n",
      "loading ...  my_images\\3.png\n",
      "loading ...  my_images\\4.png\n",
      "loading ...  my_images\\5.png\n",
      "loading ...  my_images\\6.png\n",
      "loading ...  my_images\\7.png\n",
      "loading ...  my_images\\8.png\n",
      "loading ...  my_images\\9.png\n",
      "loading ...  my_images\\digit0.png\n",
      "loading ...  my_images\\digit1.png\n",
      "loading ...  my_images\\digit2.png\n",
      "loading ...  my_images\\digit3.png\n",
      "loading ...  my_images\\digit4.png\n",
      "loading ...  my_images\\digit5.png\n",
      "loading ...  my_images\\digit6.png\n",
      "loading ...  my_images\\digit7.png\n",
      "loading ...  my_images\\digit8.png\n",
      "loading ...  my_images\\digit9.png\n"
     ]
    }
   ],
   "source": [
    "#MNIST dataset assume output_nodes = 10 for the ANN\n",
    "\n",
    "# converts the data to a format that the ANN class can use for training the model\n",
    "# this eseentially , maps a given target class label to an outputs vector (y_vec) thats compatible \n",
    "# with the ANN's output layer. \n",
    "def map_target_to_output_layer(instances, targets):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for inputs, target in zip(instances, targets):\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        y_vec = np.zeros(output_nodes) + 0.01\n",
    "        y_vec[int(target)] = 0.99\n",
    "        #print('output', target)\n",
    "        \n",
    "        X.insert(len(X), inputs) # simply inserting these they are already in the correct format\n",
    "        Y.insert(len(Y), y_vec) # inserting these after the vector mapping\n",
    "    pass\n",
    "    return(X,Y)\n",
    "pass\n",
    "\n",
    "X_my_test, y_my_test = get_my_test_data('my_images')\n",
    "X_my_test, y_my_test = map_target_to_output_layer(X_my_test, y_my_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
